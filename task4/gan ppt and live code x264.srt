1
00:00:00,000 --> 00:00:01,740
hi there I'm Luis Gomez with palo alto
你好，我是路易斯·戈麦斯和帕洛阿尔托

2
00:00:01,740 --> 00:00:04,049
education and i'd like to share with you
教育，我想和你分享

3
00:00:04,049 --> 00:00:06,330
an awesome application of machine
一个很棒的机器应用程序

4
00:00:06,330 --> 00:00:08,730
learning and neural networks this topic
学习和神经网络这个主题

5
00:00:08,730 --> 00:00:12,000
is called style transfer and what this
被称为风格转移，这是什么

6
00:00:12,000 --> 00:00:14,789
allows us to do is transfer the style of
 让我们做的就是转移风格

7
00:00:14,789 --> 00:00:17,730
one image onto another image here you
一个图像到这里你另一个图像

8
00:00:17,730 --> 00:00:20,760
see this really cool gift of an image
看到这个非常酷的图像礼物

9
00:00:20,760 --> 00:00:23,070
changing in real time and as that image
实时变化和图像变化

10
00:00:23,070 --> 00:00:26,010
changes its style is being applied to
 改变它的风格正在被应用

11
00:00:26,010 --> 00:00:28,829
the style of the man who's drawing so
 那个画画的男人的风格

12
00:00:28,829 --> 00:00:30,300
that's a really cool gift right there
那是一件很酷的礼物

13
00:00:30,300 --> 00:00:32,279
and gives you an idea of what we can do
 并让您了解我们可以做些什么

14
00:00:32,279 --> 00:00:36,179
with style transfer technology here are
这里有风格转移技术

15
00:00:36,179 --> 00:00:38,100
the major contributors to this tech
 这项技术的主要贡献者

16
00:00:38,100 --> 00:00:41,308
we've got Leon Alexander and Mattias who
我们已经有了莱昂亚历山大和马蒂亚斯谁

17
00:00:41,308 --> 00:00:43,530
all published this paper jointly called
所有发表的这篇论文共同呼吁

18
00:00:43,530 --> 00:00:46,799
a neural algorithm of artistic style
 一种艺术风格的神经算法

19
00:00:46,799 --> 00:00:49,710
it's a little bit wordy and if you have
它有点罗嗦，如果你有

20
00:00:49,710 --> 00:00:51,750
a few hours you should definitely -
 你 肯定应该几个小时 -

21
00:00:51,750 --> 00:00:52,738
through that because it's a super
通过那， 因为它是一个超级

22
00:00:52,738 --> 00:00:55,320
interesting paper but you got to set
 有趣的论文，但你必须设置

23
00:00:55,320 --> 00:00:58,619
aside some time for that one here we've
留出一些时间，一个在这里我们已经

24
00:00:58,619 --> 00:01:00,689
got some pretty applications of style
 得到了一些漂亮的风格应用

25
00:01:00,689 --> 00:01:03,539
transfer we've got the Prisma app which
转让我们有Prisma应用程序

26
00:01:03,539 --> 00:01:05,640
started to popularize this a lot more
 开始推广这个多很多

27
00:01:05,640 --> 00:01:08,579
and it's really cool as you've real-time
 你真实的时候真的很酷

28
00:01:08,579 --> 00:01:10,829
rotate around with your selfie camera
用自拍相机旋转

29
00:01:10,829 --> 00:01:13,290
you've got the style of some piece of
 你有一些片的风格

30
00:01:13,290 --> 00:01:16,650
art applied to your video and we've got
艺术应用于您的视频，我们已经

31
00:01:16,650 --> 00:01:17,868
a similar thing going on with that
与此类似的事情

32
00:01:17,868 --> 00:01:21,810
360-degree image to our tap and yeah
 360度图像到我们的水龙头和是的

33
00:01:21,810 --> 00:01:23,340
style transfer is just awesome to look
风格转让只是真棒 看

34
00:01:23,340 --> 00:01:27,659
at here I'm not gonna one run through
在这里，我不会经历一次

35
00:01:27,659 --> 00:01:28,618
all these videos there's quite a few
所有这些视频都有不少

36
00:01:28,618 --> 00:01:30,060
videos in this presentation that you
 您 在此演示文稿中的视频

37
00:01:30,060 --> 00:01:31,228
should watch on your own because they're
应该自己看，因为他们是

38
00:01:31,228 --> 00:01:33,599
super entertaining but here we've got
 超级娱乐，但我们在这里

39
00:01:33,599 --> 00:01:37,319
some oculus VR painting for you and yeah
一些眼睛VR画为你和是啊

40
00:01:37,319 --> 00:01:39,359
it's just pretty to look at man it's
 看看男人真是太好了

41
00:01:39,359 --> 00:01:42,450
just just really cool to look at so how
只是真的很酷，看看如何

42
00:01:42,450 --> 00:01:43,920
do we do this how do we accomplish this
 我们这样做是如何做到这一点的

43
00:01:43,920 --> 00:01:46,228
well we use something called a
 好吧，我们使用的东西叫做a

44
00:01:46,228 --> 00:01:48,739
generative adversarial neural network
生成对抗神经网络

45
00:01:48,739 --> 00:01:51,118
translate about 110 times fast I bet you
 翻译约110倍我打赌你

46
00:01:51,118 --> 00:01:54,090
can't okay this this is where it starts
 不能这就是它开始的地方

47
00:01:54,090 --> 00:01:57,328
to get confusing so the idea behind it
 让它变得混乱所以它背后的想法

48
00:01:57,328 --> 00:01:58,890
the basic idea behind it it's actually
 它背后的基本理念实际上就是这样

49
00:01:58,890 --> 00:02:01,259
not that difficult so we've got two
没那么难， 所以我们有两个

50
00:02:01,259 --> 00:02:03,149
neural networks if you've seen any of my
神经网络， 如果你看过我的任何一个

51
00:02:03,149 --> 00:02:04,978
previous videos on neural networks
 以前关于神经网络的视频

52
00:02:04,978 --> 00:02:07,259
before then you have an idea of what
在那之前你已经知道了什么

53
00:02:07,259 --> 00:02:09,449
we're gonna do here but if you haven't
我们会在这里做，但如果你没有

54
00:02:09,449 --> 00:02:10,500
that's totally fine too we're gonna
 我们也会完全没问题

55
00:02:10,500 --> 00:02:12,389
learn regardless so we've got a
 不管学习，我们都有

56
00:02:12,389 --> 00:02:13,870
generator neural network
发电机神经网络

57
00:02:13,870 --> 00:02:16,269
and a discriminator neural network now
现在是一个鉴别器神经网络

58
00:02:16,269 --> 00:02:18,068
an analogy that's used a ton and is
一个类似于使用了吨而且是

59
00:02:18,068 --> 00:02:20,259
super helpful for everyone in the
 每个人在超级有用

60
00:02:20,259 --> 00:02:22,598
machine learning community is to think
机器学习社区是思考

61
00:02:22,598 --> 00:02:24,729
of the generator as like a counterfeiter
 发电机就像一个伪造者

62
00:02:24,729 --> 00:02:26,709
and to think of the discriminator as
 并将鉴别器视为

63
00:02:26,709 --> 00:02:28,539
like a bank official or something like
像银行官员或类似的东西

64
00:02:28,539 --> 00:02:30,729
that whose job it is to prove the
 他的工作就是要证明这一点

65
00:02:30,729 --> 00:02:34,378
counterfeiter is making fake images so
伪造者正在伪造图像

66
00:02:34,378 --> 00:02:36,818
yeah these two are pitted against each
是的，这两个人对抗每个人

67
00:02:36,818 --> 00:02:39,159
other and over time the discriminator
其他和随着时间的推移鉴别者

68
00:02:39,159 --> 00:02:41,860
learns more and more to distinguish a
学会越来越多来区分a 

69
00:02:41,860 --> 00:02:43,900
fake image and the generator gets better
假图像和发电机变得更好

70
00:02:43,900 --> 00:02:46,360
and better at tricking the discriminator
并且更好地欺骗鉴别者

71
00:02:46,360 --> 00:02:48,579
so what is the generator how does the
 什么是发电机怎么样？

72
00:02:48,579 --> 00:02:50,289
generator work well I talked a little
发电机工作得很好我谈了一点

73
00:02:50,289 --> 00:02:51,939
bit about neural networks just now well
 关于神经网络的位刚刚好

74
00:02:51,939 --> 00:02:53,799
it generators just a neural network and
它只是一个神经网络和

75
00:02:53,799 --> 00:02:56,889
you feed it just random just garbage
你喂它只是随机只是垃圾

76
00:02:56,889 --> 00:03:01,500
just noise and it will output an image
只是噪音，它会输出一个图像

77
00:03:01,500 --> 00:03:04,299
now this image that it generates is it's
 现在它生成的这个图像就是它

78
00:03:04,299 --> 00:03:06,969
counterfeit it is the generated image
伪造它是生成的图像

79
00:03:06,969 --> 00:03:10,060
and let me talk a little bit about what
让我谈谈一下

80
00:03:10,060 --> 00:03:13,568
this latent sample is so if you've never
如果你从来没有，这个潜在的样本是如此

81
00:03:13,568 --> 00:03:15,489
seen this representation of a number
看到了一些这种表示

82
00:03:15,489 --> 00:03:17,769
before that's totally fine it's really
在此之前，它真的非常好

83
00:03:17,769 --> 00:03:20,199
rare to see outside of you know out of
很少见到外面你知道的

84
00:03:20,199 --> 00:03:24,430
machine learning so here is what that
机器学习所以这就是那个

85
00:03:24,430 --> 00:03:26,500
image is trying to show so we've got a
 图像试图显示所以我们有一个

86
00:03:26,500 --> 00:03:29,348
number one drawn here and you can see
在这里画的第一，你可以看到

87
00:03:29,348 --> 00:03:31,900
here is like a number and array
这里就像一个数字和数组

88
00:03:31,900 --> 00:03:35,560
representation of this number so all
 这个数字的表示如此全部

89
00:03:35,560 --> 00:03:37,689
these zeros correspond to all the white
这些零对应于所有的白色

90
00:03:37,689 --> 00:03:41,799
pixels in this image and these dark gray
 此图像中的像素和这些深灰色

91
00:03:41,799 --> 00:03:45,039
and all these values that are above zero
并且所有这些值是大于零

92
00:03:45,039 --> 00:03:47,680
but lower than one these represent the
但低于一个这些代表了

93
00:03:47,680 --> 00:03:53,430
gray and black pixels in this image so
 在该图像中灰色和黑色像素，从而

94
00:03:53,430 --> 00:03:56,799
this number eight right here could be
这个数字八在这里可能是

95
00:03:56,799 --> 00:04:00,340
represented in a similar way as that
 以类似的方式表示

96
00:04:00,340 --> 00:04:03,310
number one we just saw using a big array
 我们刚看到使用大阵列的第一名

97
00:04:03,310 --> 00:04:07,000
of numbers between 0 and 1 so what we do
 0到1之间的数字，所以我们做的

98
00:04:07,000 --> 00:04:10,239
is we pass the generator just these
是我们这些刚通过发电机

99
00:04:10,239 --> 00:04:13,719
random noise values and we want it to
随机噪声值，我们希望它

100
00:04:13,719 --> 00:04:17,228
generate some image like that number one
产生这样的头号一些图像

101
00:04:17,228 --> 00:04:19,870
and it does that just by picking values
它只是通过选择值来做到这一点

102
00:04:19,870 --> 00:04:22,000
between 0 and 1 and placing them in the
 介于0和1之间并将它们放入

103
00:04:22,000 --> 00:04:24,279
right spots so that's how it would work
正确的位置，这是它的工作方式

104
00:04:24,279 --> 00:04:25,870
with numbers and a similar way would
用数字和类似的方式

105
00:04:25,870 --> 00:04:27,348
work with image
与图像一起工作

106
00:04:27,348 --> 00:04:31,279
so that's the generator the counterfeit
这就是发电机的假冒伪劣

107
00:04:31,279 --> 00:04:33,918
er going back to that analogy and now we
 呃回到那个比喻，现在我们

108
00:04:33,918 --> 00:04:35,870
go to the bank official or the
去银行官员或

109
00:04:35,870 --> 00:04:37,939
discriminator the one whose job it is to
鉴别者是其工作的人

110
00:04:37,939 --> 00:04:40,668
tell that those images pass to it are
 告诉这些图像传递给它的是

111
00:04:40,668 --> 00:04:43,908
fake or real so the way the
假的还是真的如此

112
00:04:43,908 --> 00:04:45,408
discriminator works well it's just a
鉴别器运作良好它只是一个

113
00:04:45,408 --> 00:04:47,658
basic classifier neural network I say
基本的分类器神经网络我说

114
00:04:47,658 --> 00:04:51,978
basic but it's not that basic but we're
基本的，但它不是那么基本，但我们是

115
00:04:51,978 --> 00:04:53,509
gonna boss over that for now because we
 因为我们现在要坚持这个

116
00:04:53,509 --> 00:04:55,699
just want to get the ideas of machine
只是想得到机器的想法

117
00:04:55,699 --> 00:04:56,689
learning right we want those
我们想要那些正确的学习

118
00:04:56,689 --> 00:04:59,028
fundamentals because the lines of code
基础知识， 因为代码行

119
00:04:59,028 --> 00:05:00,528
will change the tools that people will
 将改变人们的工具

120
00:05:00,528 --> 00:05:02,959
use will change over time but these
使用会随着时间而 改变 但是这些

121
00:05:02,959 --> 00:05:05,718
ideas ok these are super important ideas
想法确定这些是非常重要的想法

122
00:05:05,718 --> 00:05:07,278
that are helping a lot of people in the
 正在帮助很多人在

123
00:05:07,278 --> 00:05:09,408
world right the second so the
世界第一右第二故

124
00:05:09,408 --> 00:05:11,269
discriminator is a basic classifier
鉴别器是一个基本的分类器

125
00:05:11,269 --> 00:05:15,610
neural network model and all it does is
 神经网络模型，它所做的就是

126
00:05:15,610 --> 00:05:18,259
just try to tell if an image is real or
 试着判断图像是真的还是真的

127
00:05:18,259 --> 00:05:20,689
fake so if you've seen any of my
假的，如果你看过我的任何一个

128
00:05:20,689 --> 00:05:22,579
previous videos we've talked a little
 以前的视频我们已经谈了一点

129
00:05:22,579 --> 00:05:24,649
bit about neural networks trying to tell
关于神经网络想要讲述的一点

130
00:05:24,649 --> 00:05:27,740
like a dog and a cow apart trying to
像狗和牛除了努力

131
00:05:27,740 --> 00:05:29,569
identify them when passed an image and
 传递图像时识别它们

132
00:05:29,569 --> 00:05:32,209
the way it does that is you pass it a
它的方式是你传递它

133
00:05:32,209 --> 00:05:33,740
bunch of images and they have to be
 一堆图像，他们必须

134
00:05:33,740 --> 00:05:35,629
labeled so you're throwing a bunch of
 标记为你扔了一堆

135
00:05:35,629 --> 00:05:37,759
images at the neural network and you're
 你在神经网络上的图像

136
00:05:37,759 --> 00:05:39,680
labeling them so like throw an image of
标记它们就好像抛出一个图像

137
00:05:39,680 --> 00:05:41,329
dog and make sure it comes with the
狗，并确保它附带

138
00:05:41,329 --> 00:05:43,728
label of dog throw an image of cow make
 狗的标签扔牛的图像

139
00:05:43,728 --> 00:05:45,228
sure it comes with the label of cow and
确定它带有牛和牛的标签

140
00:05:45,228 --> 00:05:47,209
you're throwing these labeled images
 你扔这些标记的图像

141
00:05:47,209 --> 00:05:48,889
into the neural network feeding it over
 进入神经网络喂它

142
00:05:48,889 --> 00:05:51,288
and over and over again and over time it
 它一遍又一遍地

143
00:05:51,288 --> 00:05:53,990
learns to extract features like curves
学会提取曲线等特征

144
00:05:53,990 --> 00:05:57,288
and lines and like distances between
和线之间的距离

145
00:05:57,288 --> 00:05:59,959
eyes and lengths of face and things like
 眼睛和长度的脸和类似的东西

146
00:05:59,959 --> 00:06:03,168
that and over time it gets really smart
 随着时间的推移，它变得非常聪明

147
00:06:03,168 --> 00:06:07,459
and it learns what in images now instead
 它现在可以学习图像中的内容

148
00:06:07,459 --> 00:06:10,069
of having two classes or instead of
 的具有两个类或代替

149
00:06:10,069 --> 00:06:12,860
having classes like animals like dogs
 像狗一样的动物课

150
00:06:12,860 --> 00:06:15,259
and cats and cows like we might have
 和 我们可能拥有的 猫和奶牛一样

151
00:06:15,259 --> 00:06:17,088
seen before with neural networks we're
 我们之前看过神经网络

152
00:06:17,088 --> 00:06:19,519
only gonna have two classes okay this is
只是要具备两个班没关系，这是

153
00:06:19,519 --> 00:06:22,550
also called a binary classifier because
也称为二元分类器因为

154
00:06:22,550 --> 00:06:26,240
we've only got two options here and the
我们只有两个选择这里和

155
00:06:26,240 --> 00:06:29,418
two options are real and fake so
两个选项是真实的和假的

156
00:06:29,418 --> 00:06:31,908
obviously it wants to be able to tell
显然它希望能够分辨出来

157
00:06:31,908 --> 00:06:34,098
that the generated images are fake and
 生成的图像是假的

158
00:06:34,098 --> 00:06:36,199
that the training data that we pass it
 我们传递的训练数据

159
00:06:36,199 --> 00:06:40,999
are real so let's put this all together
是真的所以让我们把这一切都放在一起

160
00:06:40,999 --> 00:06:43,129
with this really nice imagery right here
 这个非常好的图像就在这里

161
00:06:43,129 --> 00:06:47,809
so we've got our pull that pointer up
 所以我们把指针拉了起来

162
00:06:47,809 --> 00:06:49,728
we've got our latent sample right here
我们的潜在样本就在这里

163
00:06:49,728 --> 00:06:52,038
just random noise being fed into the
 只是随机噪声被送入

164
00:06:52,038 --> 00:06:54,499
generator the generator does some neural
 发电机发电机做了一些神经

165
00:06:54,499 --> 00:06:56,778
network stuff on it and spits out a new
网络上的东西， 并吐出一个新的

166
00:06:56,778 --> 00:07:00,110
image this is a really stupid neural
这是一个非常愚蠢的神经

167
00:07:00,110 --> 00:07:01,819
network okay it's really dumb right now
网络好吧，现在真的很蠢

168
00:07:01,819 --> 00:07:04,009
because it hasn't had a lot of training
因为它没有经过很多培训

169
00:07:04,009 --> 00:07:07,399
to go off and this discriminator right
 离开这个鉴别器吧

170
00:07:07,399 --> 00:07:09,168
now is also pretty dumb this is the
现在这也是相当愚蠢的

171
00:07:09,168 --> 00:07:10,968
beginning stages so it might not even be
开始阶段，因此甚至可能不

172
00:07:10,968 --> 00:07:13,428
able to tell the difference between this
 能告诉 这之间的区别

173
00:07:13,428 --> 00:07:16,968
and this image so as this generator is
 这个图像就像这个发生器一样

174
00:07:16,968 --> 00:07:18,769
generating images and passing it into
生成图像并将其传递给

175
00:07:18,769 --> 00:07:21,978
the discriminator we got training data
 鉴别器我们得到了训练数据

176
00:07:21,978 --> 00:07:23,838
over here and we're pooling samples out
在这里，我们正在汇集样品

177
00:07:23,838 --> 00:07:25,548
of it and also passing that to the
 它还传递给了

178
00:07:25,548 --> 00:07:27,978
discriminator so over time it's getting
鉴别者所以随着时间的推移它会越来越多

179
00:07:27,978 --> 00:07:30,408
trained on real data fake data it's
 它训练有关真实数据的假数据

180
00:07:30,408 --> 00:07:32,298
getting real data and then fake data and
获取真实数据然后伪造数据和

181
00:07:32,298 --> 00:07:35,119
it's trying to distinguish which one is
它试图区分哪个是

182
00:07:35,119 --> 00:07:37,369
real which one is fake and over time it
真实哪一个是假的，随着时间的推移呢

183
00:07:37,369 --> 00:07:39,439
learns the difference and as the
了解差异并作为

184
00:07:39,439 --> 00:07:41,928
discriminator gets smarter the generator
鉴别器使发电机更智能

185
00:07:41,928 --> 00:07:44,149
starts making better and better images
开始制作更好更好的图像

186
00:07:44,149 --> 00:07:45,468
which are more likely to fool a
哪个更容易愚弄

187
00:07:45,468 --> 00:07:47,809
discriminator here's a cool little video
鉴别家这里是一个很酷的小视频

188
00:07:47,809 --> 00:07:50,509
of the discriminator and generator being
鉴别器和发生器的存在

189
00:07:50,509 --> 00:07:53,588
trained and you can see that their
训练有素， 你可以看到他们的

190
00:07:53,588 --> 00:07:56,360
curves are getting super close generated
曲线越来越紧密

191
00:07:56,360 --> 00:07:58,788
data is starting to get super close to
数据开始越来越接近

192
00:07:58,788 --> 00:08:01,579
that real data right there and as it
真正的数据在那里，当它

193
00:08:01,579 --> 00:08:02,959
gets closer and closer that
越来越近了

194
00:08:02,959 --> 00:08:04,579
discriminator is going to get fooled
鉴别者会被愚弄

195
00:08:04,579 --> 00:08:07,069
more often which means the generator is
更常见的是发电机

196
00:08:07,069 --> 00:08:08,449
going to be putting out better and
 将会更好地推出

197
00:08:08,449 --> 00:08:12,559
better more real looking images so
更好看的真实图像

198
00:08:12,559 --> 00:08:14,629
here's an example of style transfer
这是风格转移的一个例子

199
00:08:14,629 --> 00:08:15,439
being used
正在使用

200
00:08:15,439 --> 00:08:17,988
we've got just random noise right here
我们这里只有随机噪音

201
00:08:17,988 --> 00:08:21,468
and we're applying the style of this
我们正在应用这种风格

202
00:08:21,468 --> 00:08:24,379
beautiful classic van Gogh starry night
 美丽的经典梵高繁星之夜

203
00:08:24,379 --> 00:08:27,408
and here's an example of what the image
 这是图像的一个例子

204
00:08:27,408 --> 00:08:29,988
might look like after one layer of the
看起来像的一层后，

205
00:08:29,988 --> 00:08:32,509
neural network of the generator neural
 发电机神经网络的神经网络

206
00:08:32,509 --> 00:08:34,578
network here's an example of the next
网络这里是下一个的例子

207
00:08:34,578 --> 00:08:37,099
layer the next layer and at this final
层中的下一层，并在该最终

208
00:08:37,099 --> 00:08:38,509
layer you can see it's starting to
你可以看到它开始的层

209
00:08:38,509 --> 00:08:40,938
really have the similar have a similar
真的有类似的有类似的

210
00:08:40,938 --> 00:08:46,068
vibe to this starry night image and on
感受这个繁星满天的夜晚形象

211
00:08:46,068 --> 00:08:47,899
the bottom here we get a similar type of
 这里的底部我们得到了一个相似类型的

212
00:08:47,899 --> 00:08:50,089
thing where instead of a picture of
 事情在那里 的照片，而不是

213
00:08:50,089 --> 00:08:51,948
sorry night we've got this picture of a
 对不起晚上，我们已经有了 的 这张照片

214
00:08:51,948 --> 00:08:54,740
house and we start to see it get
房子，我们开始看到它

215
00:08:54,740 --> 00:08:56,779
as the style is transferred on to that
 因为风格转移到那个

216
00:08:56,779 --> 00:09:01,429
image so here's some must-reads in
 这是一些必读的图片

217
00:09:01,429 --> 00:09:03,769
computer vision so computer vision is
计算机视觉所以计算机视觉是

218
00:09:03,769 --> 00:09:07,370
the topic of all kinds of all kinds of
各种各类的话题

219
00:09:07,370 --> 00:09:09,409
machine learning tasks and trying to get
机器学习任务并试图获得

220
00:09:09,409 --> 00:09:12,019
computers to play around with images so
 电脑玩弄图像所以

221
00:09:12,019 --> 00:09:13,940
yeah these are some good books on the
是的， 这些都是一些好书

222
00:09:13,940 --> 00:09:16,429
topic and will help you understand much
主题，将帮助您了解更多

223
00:09:16,429 --> 00:09:19,279
more of the context behind generative
 生成背后​​的背景更多

224
00:09:19,279 --> 00:09:22,490
additive behind generative adversarial
生成对抗背后的附加物

225
00:09:22,490 --> 00:09:26,720
neural networks here's a really cool
这里的神经网络非常酷

226
00:09:26,720 --> 00:09:29,090
really entertaining video on AI and art
人工智能和艺术的真实娱乐视频

227
00:09:29,090 --> 00:09:40,490
I approve of the music I'll let you
 我赞成我会告诉你的音乐

228
00:09:40,490 --> 00:09:42,350
watch that on your own time super
在你自己的时间观看超级

229
00:09:42,350 --> 00:09:43,669
entertaining really short - it's only
娱乐真的很短 - 这是唯一的

230
00:09:43,669 --> 00:09:47,659
like five minute video and here is more
 像五分钟的视频，这里更多

231
00:09:47,659 --> 00:09:50,360
of a keynote type of speech about this
 关于这一点的主题演讲

232
00:09:50,360 --> 00:09:52,970
the style transfer technology so if
 风格转移技术如果

233
00:09:52,970 --> 00:09:54,169
you're super interested in you want to
你对你想要的超级感兴趣

234
00:09:54,169 --> 00:09:56,090
dive even deeper into this I would
 更深潜入这个我会

235
00:09:56,090 --> 00:10:00,460
highly recommend watching this talk and
强烈推荐观看此演讲

236
00:10:00,460 --> 00:10:03,529
finally here's some more applications of
最后这里是一些更多的应用程序

237
00:10:03,529 --> 00:10:05,870
style transfer it's not just used to
风格转移它不仅仅是习惯

238
00:10:05,870 --> 00:10:08,120
transfer like famous paintings on to
像着名画作一样转移到

239
00:10:08,120 --> 00:10:10,700
some regular image it can also be used
一些常规图像也可以使用

240
00:10:10,700 --> 00:10:12,799
to enhance regular old photography so
 这样可以增强经常的老摄影

241
00:10:12,799 --> 00:10:15,889
here we've got this sunken Solon field
在这里，我们有了沉没的Solon领域

242
00:10:15,889 --> 00:10:17,750
right here and here we've got this
就在这里，我们已经有了这个

243
00:10:17,750 --> 00:10:20,659
beautiful rich vibrant field with a nice
 美丽富饶的充满活力的田野，很棒

244
00:10:20,659 --> 00:10:23,120
big red log cabin in the middle and by
大红色小木屋在中间和

245
00:10:23,120 --> 00:10:25,429
using style transfer we can brighten up
使用风格转移，我们可以照亮

246
00:10:25,429 --> 00:10:27,409
this image make that grass look more
这个图像使草看起来更多

247
00:10:27,409 --> 00:10:30,259
lively and give that sky a really nice
活泼，让天空变得非常好

248
00:10:30,259 --> 00:10:33,919
deep blue color and we can also do
深蓝色我们也可以做

249
00:10:33,919 --> 00:10:36,289
something like this where we have a
 像这样的东西，我们有一个

250
00:10:36,289 --> 00:10:39,259
light image and we apply to it a
光图像，我们应用到它

251
00:10:39,259 --> 00:10:42,590
beautiful sunset landscape with deep
美丽的日落景观与深

252
00:10:42,590 --> 00:10:45,230
reds and deep purples and apply that
红色和深紫色并应用它

253
00:10:45,230 --> 00:10:48,860
style to the image to make it look like
风格到图像，使它看起来像

254
00:10:48,860 --> 00:10:50,889
it was taken at night in this
这是在晚上拍摄的

255
00:10:50,889 --> 00:10:54,139
otherworldly magical location yeah I
 超凡脱俗的神奇地点，是的，我

256
00:10:54,139 --> 00:10:55,580
thought this was pretty funny style
以为这是非常有趣的风格

257
00:10:55,580 --> 00:10:57,019
transfer can also be used to transform
转移也可以用来改造

258
00:10:57,019 --> 00:10:59,960
furniture designs maybe IKEA is already
家具设计也许宜家已经是

259
00:10:59,960 --> 00:11:01,820
on the neural network hype I don't know
关于神经网络炒作我不知道

260
00:11:01,820 --> 00:11:04,190
so those are a lot of really cool
所以这些都是很多很酷的

261
00:11:04,190 --> 00:11:06,710
applications of style transfer and I
风格转移的应用和我

262
00:11:06,710 --> 00:11:08,730
think it'd be really great if we
认为，如果我们这将会是真正伟大的

263
00:11:08,730 --> 00:11:11,698
make our own right now if we could train
如果我们能够训练，现在就自己做

264
00:11:11,698 --> 00:11:14,659
our own style transfer neural networks
我们自己的风格转移神经网络

265
00:11:14,659 --> 00:11:17,039
so we're gonna use this thing called
 所以我们要用这个叫做的东西

266
00:11:17,039 --> 00:11:20,159
disco Gann now this is a pretty recent
迪斯科江恩现在这是一个非常新近

267
00:11:20,159 --> 00:11:21,659
one so it should give us some really
一个真的应该给我们一些

268
00:11:21,659 --> 00:11:24,208
cool looking results and here's a
很酷的结果，这里是一个

269
00:11:24,208 --> 00:11:26,039
flowchart of the basic process we're
 我们基本流程的流程图

270
00:11:26,039 --> 00:11:28,230
going to go through so I'll let you look
 要经过，所以我就让你看看

271
00:11:28,230 --> 00:11:29,759
over that and start thinking about how
在那之后，开始考虑如何

272
00:11:29,759 --> 00:11:31,500
we're gonna do this and I'm gonna pull
我们要这样做，我要拉

273
00:11:31,500 --> 00:11:33,480
my environment up and we're gonna run
 我的环境，我们会跑

274
00:11:33,480 --> 00:11:41,850
through some code live
 通过一些代码直播

275
00:11:41,850 --> 00:12:27,649
you
您

276
00:12:27,649 --> 00:12:29,269
all right so let's get into this live
 好的，让我们进入现场直播

277
00:12:29,269 --> 00:12:31,698
coding to do some style transfer using
 使用编码进行一些样式传输

278
00:12:31,698 --> 00:12:34,068
neural networks so we're not gonna do
 神经网络，所以我们不会这样做

279
00:12:34,068 --> 00:12:36,769
Ganz today just because the code is
 Ganz今天只是因为代码是

280
00:12:36,769 --> 00:12:39,679
super crazy to look at and to think
 超级疯狂地看待和思考

281
00:12:39,679 --> 00:12:41,749
about so instead of training two neural
关于这样而不是训练两个神经

282
00:12:41,749 --> 00:12:43,039
networks to fight against each other
 网络自相残杀

283
00:12:43,039 --> 00:12:45,019
like we talked about earlier what we're
就像我们前面谈到的就是我们

284
00:12:45,019 --> 00:12:46,458
gonna do is we're gonna use one neural
要做的是我们要使用一个神经元

285
00:12:46,458 --> 00:12:50,058
network to mix together two images this
网络将这两个图像混合在一起

286
00:12:50,058 --> 00:12:51,619
is gonna be great for you guys and
 对你们来说 会很棒

287
00:12:51,619 --> 00:12:53,360
you'll be able to still see some real
 你将能够看到一些真实的东西

288
00:12:53,360 --> 00:12:55,339
examples of styles transfer happening
 风格的例子发生转移

289
00:12:55,339 --> 00:12:56,958
right under your fingertips as we run
 在我们跑步的时候，在你的指尖

290
00:12:56,958 --> 00:12:58,759
this code holding shift and hitting
 此代码保持移位和击中

291
00:12:58,759 --> 00:13:01,278
enter allow you to run a cell here so
 输入允许你在这里运行一个单元格

292
00:13:01,278 --> 00:13:03,470
just make sure you hit shift enter and
只要确保你打移位进入和

293
00:13:03,470 --> 00:13:06,259
that'll take you through each cell so
这将带你通过每个细胞

294
00:13:06,259 --> 00:13:07,639
let's start off with cell one right here
让我们先从小区的一个就在这里

295
00:13:07,639 --> 00:13:11,448
and we run this and we see it shows us
 我们运行这个，我们看到它向我们展示

296
00:13:11,448 --> 00:13:14,448
this nice big image of content style and
 内容风格这个漂亮的大图像和

297
00:13:14,448 --> 00:13:17,419
mixed images so this is a super helpful
混合图像所以这是一个超级有用的

298
00:13:17,419 --> 00:13:18,980
graphic to refer to and gives you a
图形引用并给你一个

299
00:13:18,980 --> 00:13:20,149
really good idea of what we're gonna be
 什么 ，我们会 做得很好的主意

300
00:13:20,149 --> 00:13:22,188
doing today so we've got our content
 今天做，所以我们得到了我们的内容

301
00:13:22,188 --> 00:13:24,919
image and our style image and these are
图像和我们的风格图像，这些都是

302
00:13:24,919 --> 00:13:27,019
both being fed into the neural network
两者都被送入神经网络

303
00:13:27,019 --> 00:13:28,850
so the neural network is going to be
所以神经网络将成为现实

304
00:13:28,850 --> 00:13:31,458
extracting lines and curves from our
从我们的提取线和曲线

305
00:13:31,458 --> 00:13:33,078
content image and it's going to be
内容图片，它将会是

306
00:13:33,078 --> 00:13:35,749
extracting textures and colors from our
从我们的提取纹理和颜色

307
00:13:35,749 --> 00:13:38,600
style image and it's going to be running
风格图像，它将运行

308
00:13:38,600 --> 00:13:40,039
these through neural network extracting
 这些通过神经网络提取

309
00:13:40,039 --> 00:13:43,789
features and it's going to be adding the
 功能，它将添加

310
00:13:43,789 --> 00:13:46,100
the features that it extracts it's going
 它提取它会 功能

311
00:13:46,100 --> 00:13:48,019
to do something called calculate a
做一个叫做计算的东西

312
00:13:48,019 --> 00:13:50,328
gradient and it's going to use these
渐变，它将使用这些

313
00:13:50,328 --> 00:13:52,938
gradients that it finds to update this
 它发现更新的渐变

314
00:13:52,938 --> 00:13:56,688
blank image which will slowly over time
空白图像会慢慢地随着时间推移

315
00:13:56,688 --> 00:13:59,928
turn into a mixed image containing the
变成一个包含的混合图像

316
00:13:59,928 --> 00:14:02,120
lines from this content image and the
 来自此内容图片的行和

317
00:14:02,120 --> 00:14:03,620
textures and colors from the style image
 风格图像中的纹理和颜色

318
00:14:03,620 --> 00:14:08,089
so here we've got our imports very
所以我们这里的进口很多

319
00:14:08,089 --> 00:14:11,028
important so we've got to import this
重要的是我们必须导入这个

320
00:14:11,028 --> 00:14:13,399
right here matplotlib inline this just
就在这里matplotlib内联这个只是

321
00:14:13,399 --> 00:14:15,048
allows us to display images like this
允许我们显示这样的图像

322
00:14:15,048 --> 00:14:17,899
one in this notebook instead of popping
 一个在这个笔记本而不是弹出

323
00:14:17,899 --> 00:14:20,120
out a separate window so that's all that
出了一个单独的窗口就是这样

324
00:14:20,120 --> 00:14:23,419
does import matplotlib this is allows us
 导入matplotlib这是允许我们

325
00:14:23,419 --> 00:14:27,078
to do graphing and displaying images
做图形和显示图像

326
00:14:27,078 --> 00:14:28,698
like I said within this notebook that
就像我在这个笔记本中说的那样

327
00:14:28,698 --> 00:14:31,308
we're in here tensorflow is a library by
我们在这里tensorflow是一个库

328
00:14:31,308 --> 00:14:33,589
Google which allows us to do a lot of
 谷歌允许我们做了很多的

329
00:14:33,589 --> 00:14:35,808
common neural network tasks super easily
常见的神经网络任务非常容易

330
00:14:35,808 --> 00:14:37,480
so that's gonna save us a lot of work
 所以这会为我们节省了大量的工作

331
00:14:37,480 --> 00:14:41,220
numpy allows us to do matrix math
 numpy允许我们做矩阵数学

332
00:14:41,220 --> 00:14:43,710
and that's just complex number
这只是一个复杂的数字

333
00:14:43,710 --> 00:14:47,159
operations with we have like squares and
 我们的操作有广场和

334
00:14:47,159 --> 00:14:48,750
blocks of numbers instead of just like
数字块而不是像

335
00:14:48,750 --> 00:14:51,240
one number times one number so this
一个数字乘以一个数字所以这个

336
00:14:51,240 --> 00:14:53,370
allows us to do those matrix matrix
 允许我们做那些矩阵矩阵

337
00:14:53,370 --> 00:14:57,360
operations and pillow which we import as
我们导入的操作和枕头

338
00:14:57,360 --> 00:15:00,809
pill that image is just a library which
药丸，图像只是一个库，

339
00:15:00,809 --> 00:15:03,480
allows us to do common image tasks in
允许我们在中进行常见的图像任务

340
00:15:03,480 --> 00:15:07,379
Python and vgg 16 which is our final
 Python和vgg16这是我们的决赛

341
00:15:07,379 --> 00:15:08,909
import here is something that the author
 这里导入的是作者的东西

342
00:15:08,909 --> 00:15:11,399
has created for us and it is a wrapper
 为我们创造了它，它是一个包装

343
00:15:11,399 --> 00:15:12,210
oops
哎呀

344
00:15:12,210 --> 00:15:17,570
it is a wrapper not like M&M it is a
它是包装不喜欢M＆M 这是一个

345
00:15:17,570 --> 00:15:21,330
it's a it's a simplification that allows
这是一个允许的简化

346
00:15:21,330 --> 00:15:24,090
us to create this bgg 16 neural network
 我们来创建这个bgg16神经网络

347
00:15:24,090 --> 00:15:26,549
super easily and what this is is just
超级容易，这是什么

348
00:15:26,549 --> 00:15:28,679
like a it's just a type of neural
 就像它只是一种神经

349
00:15:28,679 --> 00:15:30,360
network and is used commonly when
网络和常用的时候

350
00:15:30,360 --> 00:15:32,490
working with images so the author curry
使用图像，所以作者咖喱

351
00:15:32,490 --> 00:15:34,679
of this of these files created us a nice
这些文件中的这些创建了我们一个很好的

352
00:15:34,679 --> 00:15:38,879
vgg 16 module that we import here that
 我们在这里导入的vgg 16模块

353
00:15:38,879 --> 00:15:41,639
allows us to create a big neural network
允许我们创建一个大的神经网络

354
00:15:41,639 --> 00:15:43,860
used for working on images super easily
用于超级轻松地处理图像

355
00:15:43,860 --> 00:15:46,620
so that's what vgg 16 does so now we're
 这就是 现在我们 所做的vgg 16所做的事情

356
00:15:46,620 --> 00:15:48,179
going to get into like the appetizer
要像 开胃菜 一样进入

357
00:15:48,179 --> 00:15:49,950
code alright this is gonna be all the
码好起来的，这是要去的所有

358
00:15:49,950 --> 00:15:51,809
helper functions that are gonna let us
帮助函数，它们将让我们

359
00:15:51,809 --> 00:15:53,700
feed our neural network in a super
 以超级的方式喂养我们的神经网络

360
00:15:53,700 --> 00:15:54,509
consistent way
 一致的方式

361
00:15:54,509 --> 00:15:58,950
so load image uses our our image library
所以加载图像使用我们的图像库

362
00:15:58,950 --> 00:16:01,559
our pillow this pill image library that
 我们的枕头这个药丸图像库

363
00:16:01,559 --> 00:16:03,960
I talked about and what it's gonna do is
 我谈到了它将要做的事情

364
00:16:03,960 --> 00:16:07,379
load images in a very specific way it's
 它以非常特定的方式加载图像

365
00:16:07,379 --> 00:16:09,000
going to load an image it's going to
 要加载它将要加载的图像

366
00:16:09,000 --> 00:16:11,309
resize it to the proper size and shape
将其调整到适当的大小和形状

367
00:16:11,309 --> 00:16:14,250
and it's going to allow us to have all
而这将让我们拥有所有

368
00:16:14,250 --> 00:16:17,399
of these images in the same exact format
 这些图像的格式相同

369
00:16:17,399 --> 00:16:18,659
this is super important when working
 这在工作时非常重要

370
00:16:18,659 --> 00:16:21,029
with neural networks any data you feed
 使用神经网络您输入的任何数据

371
00:16:21,029 --> 00:16:23,009
into it you typically want it to all be
 进入它你通常想要它

372
00:16:23,009 --> 00:16:27,149
the same type of format so same shape
 相同类型的格式如此相同的形状

373
00:16:27,149 --> 00:16:29,100
same file extension
同一文件扩展名

374
00:16:29,100 --> 00:16:31,440
all that good stuff so that's what load
所有那些好东西，这就是负载

375
00:16:31,440 --> 00:16:34,350
image does save image gets us the file
图像保存图像获取文件

376
00:16:34,350 --> 00:16:36,210
extension of JPEG and makes sure that
 JPEG的扩展，并确保

377
00:16:36,210 --> 00:16:38,789
all the images have the same color
所有图像都具有相同的颜色

378
00:16:38,789 --> 00:16:40,769
values all the same range of color
值相同的颜色范围

379
00:16:40,769 --> 00:16:43,049
values so that we've got the same exact
价值使我们得到了同样的精确度

380
00:16:43,049 --> 00:16:44,610
type of images being fed into the neural
 被送入神经的图像类型

381
00:16:44,610 --> 00:16:47,429
network plot image big just allows us to
网络情节图片大只允许我们

382
00:16:47,429 --> 00:16:49,440
plot a big image inside of this notebook
绘制这款笔记本 内部的大图

383
00:16:49,440 --> 00:16:51,299
and this is what we're going to use to
 这就是我们要用的东西

384
00:16:51,299 --> 00:16:53,789
display our final mixed image with the
 显示我们的最终混合图像

385
00:16:53,789 --> 00:16:54,809
style transfer
风格转移

386
00:16:54,809 --> 00:16:56,970
to it plot images this is just to
 对它绘制图像这只是为了

387
00:16:56,970 --> 00:16:59,009
display images nicely at the very end so
 显示图像很好地在最端部，以便

388
00:16:59,009 --> 00:17:02,669
now we get into the meat of the neural
 现在我们进入了神经的肉体

389
00:17:02,669 --> 00:17:05,519
network code here so loss functions are
网络代码在这里所以损失函数是

390
00:17:05,519 --> 00:17:07,559
a super important topic to learn about
一个值得学习的超级重要主题

391
00:17:07,559 --> 00:17:09,720
and we're not going to go into all the
而我们不会进入所有的

392
00:17:09,720 --> 00:17:10,920
math but I'm going to give you a good
数学，但我会给你一个好的

393
00:17:10,920 --> 00:17:13,349
idea of what loss functions are and why
 了解损失功能是什么以及为什么

394
00:17:13,349 --> 00:17:16,380
they're used so we give our computer a
他们被使用，所以我们给我们的电脑一个

395
00:17:16,380 --> 00:17:18,509
general direction and using a loss
总体方向和使用损失

396
00:17:18,509 --> 00:17:20,640
function machine learning algorithms are
功能机器学习算法是

397
00:17:20,640 --> 00:17:23,039
able to to get closer and closer and
能够得到密切和

398
00:17:23,039 --> 00:17:25,920
closer to that goal over time so the
 随着时间的推移接近那个目标所以

399
00:17:25,920 --> 00:17:27,240
loss function we're gonna be using here
我们将在这里使用的损失函数

400
00:17:27,240 --> 00:17:30,660
is mean squared error alright so let's
是平均误差好，所以让我们

401
00:17:30,660 --> 00:17:32,490
get into the real meat of all this
深入了解这一切

402
00:17:32,490 --> 00:17:35,069
neural network style transfer code so
神经网络样式转移代码

403
00:17:35,069 --> 00:17:36,990
this create content loss function is
这个创建内容丢失功能

404
00:17:36,990 --> 00:17:38,160
pretty important so we're gonna walk
非常重要，所以我们要走路了

405
00:17:38,160 --> 00:17:40,230
through it pretty much line by line so
 通过它几乎一行一行

406
00:17:40,230 --> 00:17:41,460
you already know by the name of the
你已经通过的名字知道

407
00:17:41,460 --> 00:17:43,019
function that it's going to have
 功能这将有

408
00:17:43,019 --> 00:17:44,279
something to do with a loss function
 与损失函数有关

409
00:17:44,279 --> 00:17:47,339
which is used to optimize in neural
 用于优化神经系统

410
00:17:47,339 --> 00:17:49,799
networks and it's also going to have to
网络，它也将不得不

411
00:17:49,799 --> 00:17:51,869
do with our content image specifically
 我们专门针对我们的内容图片

412
00:17:51,869 --> 00:17:54,359
and the content image remember is the
并且记住的内容图像是

413
00:17:54,359 --> 00:17:55,920
image that we're gonna get the curves
 我们要得到曲线的图像

414
00:17:55,920 --> 00:17:58,619
and lines from in our final style
和我们最终风格的线条

415
00:17:58,619 --> 00:18:00,210
transferred image just by the name of
 转移图像只是名称

416
00:18:00,210 --> 00:18:01,500
this function we already know a lot
 这个功能我们已经了解了很多

417
00:18:01,500 --> 00:18:03,089
about what it's going to do but let's
 关于它将要做什么，但让我们做

418
00:18:03,089 --> 00:18:04,410
dive deeper into the code and see
 深入探讨代码，看看

419
00:18:04,410 --> 00:18:06,539
exactly what's happening here so this
到底发生了什么，所以这个

420
00:18:06,539 --> 00:18:09,359
feed dict line what this is doing is
喂dict line这是做什么的

421
00:18:09,359 --> 00:18:12,990
it's telling the neural network very
它非常地告诉神经网络

422
00:18:12,990 --> 00:18:15,179
explicitly hey we're going to feed you
显然， 嘿，我们要喂你

423
00:18:15,179 --> 00:18:16,589
an image and the image we're going to
一个图像和我们要去的图像

424
00:18:16,589 --> 00:18:18,329
feed you is this content image right
喂你就是这个内容形象吧

425
00:18:18,329 --> 00:18:19,890
here and if you're wondering where that
 在这里，如果你想知道在哪里

426
00:18:19,890 --> 00:18:21,450
content image is coming through well
 内容图片很顺利

427
00:18:21,450 --> 00:18:23,819
it's right up here it's going to get
 它就在这里它会得到

428
00:18:23,819 --> 00:18:26,400
passed into this function as we call it
 我们称之为传递给这个函数

429
00:18:26,400 --> 00:18:30,420
so layers this line right here is going
 所以层这条线在这里是怎么回事

430
00:18:30,420 --> 00:18:34,440
to get the the layers that the fed image
 得到的层，所述馈图像

431
00:18:34,440 --> 00:18:37,250
is moving through in the neural network
正在通过神经网络

432
00:18:37,250 --> 00:18:40,950
so here we tell the model hey this is
所以在这里我们告诉模型嘿这是

433
00:18:40,950 --> 00:18:42,480
the image we want to feed to you and
 我们想要给你的形象

434
00:18:42,480 --> 00:18:45,450
this line is saying hey give me all the
这条线说嘿，给我所有的

435
00:18:45,450 --> 00:18:47,160
layers that this image is going to move
层， 该图像将移动

436
00:18:47,160 --> 00:18:51,059
through now we're going to calculate the
 到现在为止我们要计算一下

437
00:18:51,059 --> 00:18:55,890
actual values that the image now we're
 现在我们的图像的实际值

438
00:18:55,890 --> 00:18:57,630
going to calculate the actual values
 要计算实际值

439
00:18:57,630 --> 00:18:59,640
that the neural network calculates when
 神经网络计算何时

440
00:18:59,640 --> 00:19:01,920
we move the image through the layers of
我们通过层层移动图像

441
00:19:01,920 --> 00:19:03,509
the neural network which we received
 我们收到的神经网络

442
00:19:03,509 --> 00:19:06,900
here so the way we do that is using this
 在这里，我们这样做的方式就是使用它

443
00:19:06,900 --> 00:19:08,868
super nice tensor flow
超级好的张量流

444
00:19:08,868 --> 00:19:12,929
function just called session run and all
函数刚刚调用会话运行和所有

445
00:19:12,929 --> 00:19:14,999
we do is we give it layers and we give
我们做的是我们给它层，我们给

446
00:19:14,999 --> 00:19:17,848
it an image the results of running that
它是运行结果的图像

447
00:19:17,848 --> 00:19:19,348
image through all those layers that
通过所有这些层图像即

448
00:19:19,348 --> 00:19:21,269
needs to go through will be now stored
需要通过将现在存储

449
00:19:21,269 --> 00:19:24,388
in the values variable so what this is
 在值变量中，这是什么

450
00:19:24,388 --> 00:19:26,429
doing is just making a big placeholder
做就是做一个大占位符

451
00:19:26,429 --> 00:19:28,169
for all the losses we're about to be
因为我们即将面临的所有损失

452
00:19:28,169 --> 00:19:31,259
computing and this for loop right here
计算和这个for循环就在这里

453
00:19:31,259 --> 00:19:33,659
so remember value is all the values
所以记住价值就是所有的价值观

454
00:19:33,659 --> 00:19:35,219
after the image has been passed through
 图像通过后

455
00:19:35,219 --> 00:19:38,009
all the layers and layer is all of the
 所有的层和层都是

456
00:19:38,009 --> 00:19:39,778
layers of the neural network that the
那层神经网络

457
00:19:39,778 --> 00:19:41,548
image is going to be passed through so
图像是要通过这样传递

458
00:19:41,548 --> 00:19:43,679
we're going to move through all of these
我们正在经历所有 这些 移动

459
00:19:43,679 --> 00:19:45,239
values and layers and we're going to
 价值观和层次，我们要去

460
00:19:45,239 --> 00:19:48,269
apply a loss function to each layer and
 对每一层都 应用一个损失函数

461
00:19:48,269 --> 00:19:52,319
each value so we apply that loss
每个值， 所以我们应用该损失

462
00:19:52,319 --> 00:19:54,118
function store it in this lost variable
函数将它存储在这个丢失的变量中

463
00:19:54,118 --> 00:19:56,729
and then we toss that into our big
然后我们把它扔进我们的大

464
00:19:56,729 --> 00:20:00,088
placeholder layer losses so this is
 占位符层损失所以这是

465
00:20:00,088 --> 00:20:02,308
actually not going to hold any values
实际上不会持有任何价值观

466
00:20:02,308 --> 00:20:04,499
for now this is just going to hold loss
现在这只是亏本

467
00:20:04,499 --> 00:20:06,659
functions so we're gonna store the
功能所以我们要存储

468
00:20:06,659 --> 00:20:08,489
functions that we want to run later in
 我们要在以后运行功能

469
00:20:08,489 --> 00:20:12,058
this array and total loss once we've
 一旦我们这个阵列和全部损失

470
00:20:12,058 --> 00:20:13,950
stored all of those loss functions in
存储了所有这些损失函数

471
00:20:13,950 --> 00:20:16,440
the array and we exit this loop we're
数组， 我们退出这个循环

472
00:20:16,440 --> 00:20:18,358
gonna hop back out of there and we're
要跳出那里，我们就是

473
00:20:18,358 --> 00:20:20,489
going to just take the average of all
 要只取 所有的平均值

474
00:20:20,489 --> 00:20:21,929
those loss functions and what they
那些损失的功能和它们是什么

475
00:20:21,929 --> 00:20:24,269
computed and we're going to return this
 计算，我们将返回此

476
00:20:24,269 --> 00:20:26,788
total loss high level idea of what this
总亏损高水平的想法是什么

477
00:20:26,788 --> 00:20:29,608
function is doing is it's feeding the
 功能做的是它的喂养

478
00:20:29,608 --> 00:20:32,368
neural network our content image which
神经网络我们的内容图像

479
00:20:32,368 --> 00:20:34,769
we want to find lines and shapes of it's
我们想找到线条和形状的这

480
00:20:34,769 --> 00:20:36,148
feeding our neural network that image
为我们的神经网络提供图像

481
00:20:36,148 --> 00:20:38,069
through some very specific layers and
通过一些非常具体的层和

482
00:20:38,069 --> 00:20:40,319
then it's using something called a loss
那么它正在使用一种称为损失的东西

483
00:20:40,319 --> 00:20:44,338
function to calculate an optimization I
函数计算优化I

484
00:20:44,338 --> 00:20:45,690
don't know how you're going to extract
不知道你将如何提取

485
00:20:45,690 --> 00:20:48,169
features but use this loss function and
 功能，但使用此损失功能和

486
00:20:48,169 --> 00:20:50,999
that's your direction all right so now
这就是你现在的方向

487
00:20:50,999 --> 00:20:52,528
we're gonna do something similar with
我们该怎么做类似的事情

488
00:20:52,528 --> 00:20:54,838
the style image so what we're gonna do
风格的形象， 所以我们要做的

489
00:20:54,838 --> 00:20:56,548
is use this thing called a gram matrix
使用这个称为克矩阵的东西

490
00:20:56,548 --> 00:20:59,249
and we don't need to know exactly what a
 我们不需要确切地知道什么是

491
00:20:59,249 --> 00:21:00,898
grande matrix is because that's a big
格兰德矩阵是因为这是一个很大的

492
00:21:00,898 --> 00:21:04,019
linear algebra thing so we're just gonna
线性代数的事情， 所以我们要去

493
00:21:04,019 --> 00:21:06,749
keep in mind that this whole purpose of
请记住这个目的

494
00:21:06,749 --> 00:21:09,989
the gram matrix is to figure out which
克矩阵是要弄清楚哪个

495
00:21:09,989 --> 00:21:12,959
features in the style layers of the
 样式层中的特征

496
00:21:12,959 --> 00:21:15,989
neural network will activate when we
神经网络将在我们激活时激活

497
00:21:15,989 --> 00:21:18,808
pass it in the style image and then when
将它传递给样式图像然后何时传递

498
00:21:18,808 --> 00:21:21,298
we find out what parts of the style
我们找出了风格的哪些部分

499
00:21:21,298 --> 00:21:22,349
layers in the neural net
神经网络中的层

500
00:21:22,349 --> 00:21:24,119
are activating when we pass it the style
 当我们传递它的风格时激活

501
00:21:24,119 --> 00:21:26,880
image we're going to copy this into our
我们要把它复制到我们的图片中

502
00:21:26,880 --> 00:21:29,369
mixed image and what that does is
混合图像和它的作用

503
00:21:29,369 --> 00:21:31,528
basically extract all the colors and
 基本上提取所有的颜色和

504
00:21:31,528 --> 00:21:33,869
textures from our style image paste that
 我们的样式图像粘贴的纹理

505
00:21:33,869 --> 00:21:36,929
into the mixed image so just like up
进入混合图像就好了

506
00:21:36,929 --> 00:21:40,079
here with the content loss where we're
 这里的内容丢失我们在哪里

507
00:21:40,079 --> 00:21:42,509
extracting all the contours all the
 全部提取所有轮廓

508
00:21:42,509 --> 00:21:44,970
lines all the shapes out of our content
排列我们内容的所有形状

509
00:21:44,970 --> 00:21:47,369
image and pasting that into the mixed
 图像和粘贴到混合

510
00:21:47,369 --> 00:21:51,450
image here is where this Graham matrix
这里的图像就是这个格雷厄姆矩阵

511
00:21:51,450 --> 00:21:53,369
function and this create style loss is
功能和这创造风格损失是

512
00:21:53,369 --> 00:21:56,429
what's going to allow us to copy and
什么会让我们复制和

513
00:21:56,429 --> 00:21:59,369
paste the colors and textures from our
 粘贴颜色和纹理我们

514
00:21:59,369 --> 00:22:02,940
style image into the mixed image all
风格图像全部融入混合图像

515
00:22:02,940 --> 00:22:05,759
right so this create denoise loss this
这样就可以减少这种损失

516
00:22:05,759 --> 00:22:08,069
is yet another loss function but we're
 是另一个损失函数，但我们是

517
00:22:08,069 --> 00:22:09,419
not going to talk about this one because
不打算谈论这个，因为一个

518
00:22:09,419 --> 00:22:10,769
it's not as important as the other two
它没有其他两个那么重要

519
00:22:10,769 --> 00:22:13,769
all that this one does is make the image
所有这一切都是制作图像

520
00:22:13,769 --> 00:22:16,169
a little bit clearer so we're not going
 更清楚一点， 所以我们不去

521
00:22:16,169 --> 00:22:17,579
to talk about that for now but make sure
 现在 谈谈这个， 但要确保

522
00:22:17,579 --> 00:22:19,819
to run it again with shift-enter and
 用shift-enter再次运行它

523
00:22:19,819 --> 00:22:22,619
here is where we actually do the style
这里是我们实际风格的地方

524
00:22:22,619 --> 00:22:24,210
transferring this is what's going to run
转移这是将要运行的

525
00:22:24,210 --> 00:22:25,648
both of those loss functions that we
这两方面的损失函数，我们

526
00:22:25,648 --> 00:22:28,230
created earlier and actually combine
 早期创建并实际组合

527
00:22:28,230 --> 00:22:30,148
them and paste them into our mixed image
将它们粘贴到我们的混合图像中

528
00:22:30,148 --> 00:22:31,798
so we're going to use something called
 所以我们要用一些叫做的东西

529
00:22:31,798 --> 00:22:34,679
gradient descent now gradient descent is
梯度下降现在梯度下降了

530
00:22:34,679 --> 00:22:39,028
a way of finding the local minimum and
 寻找当地最低点和最低点的方法

531
00:22:39,028 --> 00:22:40,950
we want to find the local minimum
我们想找到当地的最低要求

532
00:22:40,950 --> 00:22:43,349
because we want our loss to be as small
 因为我们希望我们的损失一样小

533
00:22:43,349 --> 00:22:45,690
as possible because when our loss is as
 作为可能的，因为当我们的损失是

534
00:22:45,690 --> 00:22:47,819
small as possible our mixed image will
 我们的混合图像会尽可能小

535
00:22:47,819 --> 00:22:49,648
have the most of the contours that it
拥有它的大部分轮廓

536
00:22:49,648 --> 00:22:52,288
can get from our content image and the
可以从我们的内容图像和

537
00:22:52,288 --> 00:22:55,679
most possible amount of colors and
最可能的颜色和

538
00:22:55,679 --> 00:22:58,589
textures as it can have from our style
它可以从我们的风格中获得纹理

539
00:22:58,589 --> 00:23:00,599
image so our goal right here is to
图像所以我们的目标就在这里

540
00:23:00,599 --> 00:23:02,250
minimize both of those loss functions
最小化这两种损失函数

541
00:23:02,250 --> 00:23:03,929
that we created earlier and the way we
我们之前创建的以及我们的方式

542
00:23:03,929 --> 00:23:05,369
do that is this technique called
这就是这种技术

543
00:23:05,369 --> 00:23:07,619
gradient descent so the idea behind
 渐渐下降所以背后的想法

544
00:23:07,619 --> 00:23:10,169
gradient descent is like if you think of
梯度下降就像你想到的那样

545
00:23:10,169 --> 00:23:13,349
of like a ball rolling down a hill the
就像一个滚下山坡的球

546
00:23:13,349 --> 00:23:15,179
way that a ball rolls down a hill it
球滚下山的方式

547
00:23:15,179 --> 00:23:18,000
doesn't go from like here all the way to
不是像这里一直走到的

548
00:23:18,000 --> 00:23:20,359
the bottom of the hill right a ball
 山脚下右边一个球

549
00:23:20,359 --> 00:23:24,359
incrementally rolls down the hill and if
逐渐滚下山坡，如果

550
00:23:24,359 --> 00:23:25,859
there are like some curves in the
有一些曲线

551
00:23:25,859 --> 00:23:27,750
hillside the ball might have to take a
 球在山坡上可能需要拿一个

552
00:23:27,750 --> 00:23:30,089
bit of a winding path to get to the
 蜿蜒的小路位才能到

553
00:23:30,089 --> 00:23:32,028
bottom gradient descent is the same idea
底部梯度下降是同一个想法

554
00:23:32,028 --> 00:23:36,160
so except instead of walking down
 所以除了不要走路

555
00:23:36,160 --> 00:23:39,369
Hill we're walking down a like 50
 希尔我们走了50级

556
00:23:39,369 --> 00:23:40,930
dimensional who knows how many
维谁知道多少

557
00:23:40,930 --> 00:23:43,480
dimensions to get to the bottom of that
 要达到底部的尺寸

558
00:23:43,480 --> 00:23:45,190
loss function space
损失函数空间

559
00:23:45,190 --> 00:23:49,480
so yeah that's what gradient descent so
所以是的，这就是梯度下降所以

560
00:23:49,480 --> 00:23:52,299
we're gonna use gradient descent to get
我们将使用渐变下降来获得

561
00:23:52,299 --> 00:23:54,970
our loss as small as possible to make
我们尽可能小的损失，使

562
00:23:54,970 --> 00:23:56,980
sure we can pull as many features as
 我们确定可以提取尽可能多的功能

563
00:23:56,980 --> 00:23:59,319
possible out of our content image and
 我们的内容图片和

564
00:23:59,319 --> 00:24:01,329
our style image to combine them into our
我们的风格形象将它们融入我们的

565
00:24:01,329 --> 00:24:05,410
mixed image so yeah that's the big idea
混合图像所以是的，这是个大主意

566
00:24:05,410 --> 00:24:08,309
with this style transfer function and
 具有这种风格转移功能和

567
00:24:08,309 --> 00:24:12,039
here you see we're doing our nice tensor
在这里，你看到我们正在做着很好的张量

568
00:24:12,039 --> 00:24:14,259
flow stuff we're going to get the layers
 流动的东西，我们将得到层

569
00:24:14,259 --> 00:24:16,180
of the neural network we want to use
 我们想要使用的神经网络

570
00:24:16,180 --> 00:24:18,670
which is our we're getting different
这是我们的不同之处

571
00:24:18,670 --> 00:24:20,410
layers out of the neural network we want
 层出我们想要 的神经网络

572
00:24:20,410 --> 00:24:23,380
to use here and here and these are
在这里和这里使用这些都是

573
00:24:23,380 --> 00:24:25,630
content layers and our style layers so
内容层和我们的风格层，从而

574
00:24:25,630 --> 00:24:27,279
we're going to be using different layers
我们将使用不同的图层

575
00:24:27,279 --> 00:24:28,960
for the content image and the style
对于内容图像和样式

576
00:24:28,960 --> 00:24:33,130
image and here we make that loss
图像，在这里我们做了那个损失

577
00:24:33,130 --> 00:24:35,950
function using those those methods that
功能使用那些方法

578
00:24:35,950 --> 00:24:37,380
we defined above
 我们在上面定义

579
00:24:37,380 --> 00:24:40,000
so we've got loss for our content image
所以我们的内容图片已经丢失了

580
00:24:40,000 --> 00:24:44,289
loss for our style image and again loss
 失去我们的风格形象，再次失去

581
00:24:44,289 --> 00:24:46,180
for the D noise but we don't want to
对于D噪声，但我们不想

582
00:24:46,180 --> 00:24:47,829
focus on this right now all this does is
关注这个，现在所有这样做是

583
00:24:47,829 --> 00:24:49,390
help the image be a little bit less
帮助图像少一点

584
00:24:49,390 --> 00:24:55,509
noisy so yeah now we're getting the
吵，所以是的， 现在我们得到了

585
00:24:55,509 --> 00:24:58,269
actual variables and in tensor flow what
 实际变量和张量流量是什么

586
00:24:58,269 --> 00:25:01,480
a variable is is some value that we want
变量是我们想要的一些值

587
00:25:01,480 --> 00:25:04,509
to change so telling tensorflow that
 改变这样告诉tensorflow那

588
00:25:04,509 --> 00:25:06,250
you're making a new variable is telling
你正在制作一个新的变量

589
00:25:06,250 --> 00:25:09,160
it hey make sure after every iteration
 嘿 每次迭代后确认

590
00:25:09,160 --> 00:25:11,319
of running those loss functions make
运行那些损失函数

591
00:25:11,319 --> 00:25:14,289
sure you update the variables so the
确定你更新变量所以

592
00:25:14,289 --> 00:25:16,450
variables we want to update are the
我们想要更新的变量是

593
00:25:16,450 --> 00:25:18,430
content variables and the style
内容变量和样式

594
00:25:18,430 --> 00:25:20,559
variables because over time we want to
变量， 因为我们想要 随着时间的推移

595
00:25:20,559 --> 00:25:21,640
be able to pull more and more
能够拉越来越多

596
00:25:21,640 --> 00:25:24,730
information out of these images and we
 这些图像和我们的信息

597
00:25:24,730 --> 00:25:26,440
also make a variable for the D noise
也为D噪音制作变量

598
00:25:26,440 --> 00:25:28,029
just like we did earlier but we're gonna
 就像我们之前做的那样，但我们会的

599
00:25:28,029 --> 00:25:29,470
continue glossing over this because
继续掩盖这一点， 因为

600
00:25:29,470 --> 00:25:31,750
remember anytime you see D noise in this
记得任何时候你看到D噪音

601
00:25:31,750 --> 00:25:33,849
file all it's doing is helping to make
 文件所做的一切正在帮助制作

602
00:25:33,849 --> 00:25:36,160
the image a little bit clearer and less
图像更清晰，更少

603
00:25:36,160 --> 00:25:39,849
noisy so now we're going to make a new
吵，所以现在我们要做一个新的

604
00:25:39,849 --> 00:25:42,970
tensorflow session using this session
 使用此会话的tensorflow会话

605
00:25:42,970 --> 00:25:46,690
run call and all that does is allows
 运行调用，所有这一切都是允许的

606
00:25:46,690 --> 00:25:49,750
tensorflow to build this big graph of
 tensorflow构建这个大图

607
00:25:49,750 --> 00:25:51,400
all the mathematical stuff that it needs
它需要的所有数学东西

608
00:25:51,400 --> 00:25:55,390
to do and we get to do that just one
 要做，我们只做一个

609
00:25:55,390 --> 00:25:57,910
line using session dot run and passing
使用会话点运行和传递的行

610
00:25:57,910 --> 00:25:59,740
it the things that we wanted to do
它是我们想要做的事情

611
00:25:59,740 --> 00:26:01,869
computations on so that's really cool
计算， 这真的很酷

612
00:26:01,869 --> 00:26:03,519
tensor flow is a real game changer when
张量流是一个真正的游戏改变者

613
00:26:03,519 --> 00:26:05,910
it came out so here is where we actually
它出来了，所以这里是我们实际的地方

614
00:26:05,910 --> 00:26:10,839
tell tensor flow how to update those so
 告诉张量流如何更新那些

615
00:26:10,839 --> 00:26:13,390
here is where we're writing the code
这是我们编写代码的地方

616
00:26:13,390 --> 00:26:16,240
that tells tensor flow how much to
这告诉张量流量到底有多少

617
00:26:16,240 --> 00:26:19,150
update our variables by and make sure
通过更新我们的变量并确保

618
00:26:19,150 --> 00:26:21,309
that it's just the tiniest incremental
它只是最微小的增量

619
00:26:21,309 --> 00:26:23,470
improvement because we want to descend
改善， 因为我们想要下降

620
00:26:23,470 --> 00:26:27,400
slowly okay the big thing with using
慢慢好 使用的一件大事

621
00:26:27,400 --> 00:26:29,740
gradient descent is if you imagine that
梯度下降就是你想象的那样

622
00:26:29,740 --> 00:26:32,049
if you imagine that ball rolling down a
 如果你想象那个球滚下来了

623
00:26:32,049 --> 00:26:35,349
hill example a ball can roll down a hill
山例如一个球可以滚下山

624
00:26:35,349 --> 00:26:40,210
and then roll back and forth right we
 然后我们来回滚动吧

625
00:26:40,210 --> 00:26:43,119
don't want that so we want our ball to
不要那样我们想要我们的球

626
00:26:43,119 --> 00:26:45,359
move a little slower we want it to move
移动速度慢一点，我们希望它移动

627
00:26:45,359 --> 00:26:48,039
we want it to move down in tiny little
我们希望它在微小的一点点向下移动

628
00:26:48,039 --> 00:26:50,829
steps so that it doesn't overshoot and
步骤， 以便它不会超调和

629
00:26:50,829 --> 00:26:52,420
come up the start coming up the other
 从另一个开始出现

630
00:26:52,420 --> 00:26:55,240
side of the hill here's where we combine
 这边的山坡是我们结合的地方

631
00:26:55,240 --> 00:26:58,210
the loss here is the part where we're
 这里的损失是我们所在的部分

632
00:26:58,210 --> 00:27:00,269
going to actually combine those losses
 实际上将这些损失结合起来

633
00:27:00,269 --> 00:27:03,009
get that gradient that we calculated up
 得到我们计算出的渐变

634
00:27:03,009 --> 00:27:04,960
here getting all of those tensors
在这里得到所有这些张量

635
00:27:04,960 --> 00:27:08,440
getting all those big big squares of
得到所有那些大的广场

636
00:27:08,440 --> 00:27:09,730
numbers that we want to start updating
 我们想要开始更新的数字

637
00:27:09,730 --> 00:27:11,799
and store them in this run list variable
 并将它们存储在此运行列表变量中

638
00:27:11,799 --> 00:27:14,109
and mixed image here's where we
 和混合图像在这里我们

639
00:27:14,109 --> 00:27:16,000
initialize our mixed image so all we're
初始化我们的混合图像所以我们都是

640
00:27:16,000 --> 00:27:19,599
gonna do with this is make a new big
这将是一个新的大事

641
00:27:19,599 --> 00:27:21,490
block of pixels which will represent a
 将代表a的像素块

642
00:27:21,490 --> 00:27:24,339
new image and just fill it with random
 新图像，只需随机填写

643
00:27:24,339 --> 00:27:26,589
noise that's all that the mix image is
噪音就是混合图像的全部

644
00:27:26,589 --> 00:27:29,140
going to start out as and now we feed
 从头开始，现在我们喂

645
00:27:29,140 --> 00:27:30,759
our mixed image into the neural network
我们的混合图像进入神经网络

646
00:27:30,759 --> 00:27:32,529
so that it can start getting all those
这样它就可以开始获得所有这些

647
00:27:32,529 --> 00:27:34,599
features out of our content and style
 我们的内容和风格

648
00:27:34,599 --> 00:27:38,049
image and yeah and that that's pretty
图像，是的，那很漂亮

649
00:27:38,049 --> 00:27:39,640
much what the rest of this code does is
 这个代码的其余部分是做什么的

650
00:27:39,640 --> 00:27:41,380
it feeds the mixed image into the neural
 它将混合图像输入神经元

651
00:27:41,380 --> 00:27:44,019
network at the same time as the content
网络同时作为内容

652
00:27:44,019 --> 00:27:45,880
and style imagers are going in to
 和风格成像仪进入

653
00:27:45,880 --> 00:27:47,890
extract their features and the mixed
提取他们的特征和混合

654
00:27:47,890 --> 00:27:49,809
image is going in right along with them
图像与他们的权利以及 在去

655
00:27:49,809 --> 00:27:51,940
so that it can get applied all of the
 这样它就可以应用所有的

656
00:27:51,940 --> 00:27:53,140
features that the neural network is
 神经网络的特征

657
00:27:53,140 --> 00:27:56,609
extracting on our other two images and
提取我们的其他两个图像和

658
00:27:56,609 --> 00:27:59,470
yeah that's it that's all the neural
是的，这就是所有的神经

659
00:27:59,470 --> 00:28:02,799
network code alright cool so let's run
网络代码好吧，所以让我们运行

660
00:28:02,799 --> 00:28:03,308
this
这个

661
00:28:03,308 --> 00:28:06,460
shift-enter so it's okay if you didn't
 shift-enter 所以如果你没有，那也没关系

662
00:28:06,460 --> 00:28:10,089
understand most or any of that really
了解大多数或任何真正的

663
00:28:10,089 --> 00:28:11,378
what I want you to get out of that is
 我想让你摆脱的是

664
00:28:11,378 --> 00:28:14,679
the high-level idea of being able to
能够的高层次想法

665
00:28:14,679 --> 00:28:18,548
feed images into a neural network trying
将图像输入神经网络尝试

666
00:28:18,548 --> 00:28:20,829
to think about loss functions and
考虑损失函数和

667
00:28:20,829 --> 00:28:22,808
gradient descent and just so you can see
梯度下降，你可以看到

668
00:28:22,808 --> 00:28:24,460
some of the real-life code that we use
 我们使用的一些现实代码

669
00:28:24,460 --> 00:28:26,829
in machine learning and the real actual
在机器学习和真实的实际

670
00:28:26,829 --> 00:28:29,829
tools that we use so and yeah I just
我们使用的工具，是的，我只是

671
00:28:29,829 --> 00:28:32,079
want you to expose you to those concepts
 希望您向您展示这些概念

672
00:28:32,079 --> 00:28:34,450
and show you how we use them in real
 并告诉你我们如何在真实中使用它们

673
00:28:34,450 --> 00:28:37,990
life code so don't worry if you didn't
 生活密码所以不要担心，如果你没有

674
00:28:37,990 --> 00:28:39,398
understand most of that it's totally
 完全理解它的大部分内容

675
00:28:39,398 --> 00:28:41,259
fine it'll take you a while to
很好， 它会花费你一段时间

676
00:28:41,259 --> 00:28:43,659
understand all this stuff it took me it
了解它带给我的所有这些东西

677
00:28:43,659 --> 00:28:45,339
took me along a long time and I'm still
带我走了很长一段时间，我还在

678
00:28:45,339 --> 00:28:47,319
learning new stuff about this every day
 每天都在学习新的东西

679
00:28:47,319 --> 00:28:49,509
pretty much so here's an example of how
几乎所以这里有一个如何的例子

680
00:28:49,509 --> 00:28:51,308
to take all that code that we just wrote
 把所有的代码，我们只是写

681
00:28:51,308 --> 00:28:54,700
and how to actually run our images right
以及如何正确运行我们的图像

682
00:28:54,700 --> 00:28:57,159
because we never specified like hey take
 因为我们从来没有像嘿那样指定

683
00:28:57,159 --> 00:28:59,378
this style image and take this content
 这个风格的形象，并采取这个内容

684
00:28:59,378 --> 00:28:59,859
image
图片

685
00:28:59,859 --> 00:29:01,298
well this code is going to show you how
那么这段代码将告诉你如何

686
00:29:01,298 --> 00:29:03,069
to actually feed the images that you
 实际上喂你的图像

687
00:29:03,069 --> 00:29:05,769
want into that neural network and do all
想要进入那个神经网络并做所有事情

688
00:29:05,769 --> 00:29:07,720
of that style transferring stuff so
这种风格转移的东西

689
00:29:07,720 --> 00:29:09,700
here's an example we're gonna load this
这是一个例子， 我们要加载它

690
00:29:09,700 --> 00:29:12,159
willy wonka old image and that's just
 威利wonka老图像，这是公正的

691
00:29:12,159 --> 00:29:15,940
stored in this images folder and it's
存储在此图像文件夹中，它是

692
00:29:15,940 --> 00:29:16,450
called
叫

693
00:29:16,450 --> 00:29:20,440
willy wonka old so you can see it's just
 willy wonka old所以你可以看到它只是

694
00:29:20,440 --> 00:29:23,169
getting going into that images directory
进入该图像目录

695
00:29:23,169 --> 00:29:25,089
and getting that oops images directory
并得到那个oops图像目录

696
00:29:25,089 --> 00:29:26,829
and getting that willy wonka old that
并得到了那个willy wonka那个

697
00:29:26,829 --> 00:29:29,919
jpg image using that load image function
使用该加载图像功能的 jpg图像

698
00:29:29,919 --> 00:29:32,230
we talked about way back up here to just
 我们谈论的方式回到了这里只是

699
00:29:32,230 --> 00:29:34,118
load that image in a very specific way
 以非常特定的方式加载该图像

700
00:29:34,118 --> 00:29:36,730
and we do the same thing for our style
我们为自己的风格做同样的事情

701
00:29:36,730 --> 00:29:39,190
image and this is located in the same
图像和它位于相同的位置

702
00:29:39,190 --> 00:29:41,710
folder right here and it's just called
 文件夹就在这里，它刚刚被调用

703
00:29:41,710 --> 00:29:45,878
style 7 so let's hit shift enter to load
样式7所以让我们点击shift进入加载

704
00:29:45,878 --> 00:29:48,909
these we're going to use only the fourth
这些我们只会使用第四个

705
00:29:48,909 --> 00:29:52,269
layer of our vgg 16 neural network to
我们的vgg 16神经网络层

706
00:29:52,269 --> 00:29:55,628
get the contours and the lines out of
得到的轮廓和线条出来

707
00:29:55,628 --> 00:29:58,329
our content image this is just like an
我们的内容图片就像一个

708
00:29:58,329 --> 00:30:00,099
experimentation thing the author just
作者只做实验

709
00:30:00,099 --> 00:30:02,048
tried a bunch of different layers to see
尝试了一堆不同的层来看

710
00:30:02,048 --> 00:30:04,298
which one was getting the best lines out
其中之一是得到最好的线条勾勒出

711
00:30:04,298 --> 00:30:06,519
of the content image and it just turned
 内容画面的，它刚满

712
00:30:06,519 --> 00:30:08,829
out that 4 was the best layer of the
 指出，4是的最佳层

713
00:30:08,829 --> 00:30:10,538
neural network to extract lines and
神经网络提取线和

714
00:30:10,538 --> 00:30:12,878
contours so we're using that fourth
 轮廓所以我们正在使用第四个

715
00:30:12,878 --> 00:30:17,140
layer and now we're getting all of
层，现在我们得到了所有

716
00:30:17,140 --> 00:30:20,920
the layers the bgg 16 model has 13
 的BGG 16模型具有13层

717
00:30:20,920 --> 00:30:23,170
layers and here we're just getting all
层，在这里， 我们只是得到了所有

718
00:30:23,170 --> 00:30:25,420
13 of those layers to run our style
 这些图层中有 13 个是我们的风格

719
00:30:25,420 --> 00:30:29,049
image through and now we've run our
图像通过，现在我们运行我们的

720
00:30:29,049 --> 00:30:32,259
style transfer function and train our
风格转移功能和训练我们的

721
00:30:32,259 --> 00:30:34,599
neural network to transfer the style of
神经网络转移的风格

722
00:30:34,599 --> 00:30:38,170
one image and to combine the textures
一个图像和组合纹理

723
00:30:38,170 --> 00:30:40,480
and colors from one image and the lines
 和一个图像和线条的颜色

724
00:30:40,480 --> 00:30:42,609
and shapes from another image into a
 从另一个图像到另一个图像的形状

725
00:30:42,609 --> 00:30:45,730
mixed image to create our final style
混合图像来创造我们的最终风格

726
00:30:45,730 --> 00:30:49,599
transfer result and yeah just run that
转移结果，是的，只是运行

727
00:30:49,599 --> 00:30:51,460
and thankfully I have a pretty fast
谢天谢地，我的速度很快

728
00:30:51,460 --> 00:30:52,839
computer so I'll just show you the
电脑，所以我只会告诉你

729
00:30:52,839 --> 00:30:55,750
training right here and yeah we'll see
 在这里训练，是的，我们会看到

730
00:30:55,750 --> 00:30:58,109
how all these images are printed out and
 如何将所有这些图像打印出来，

731
00:30:58,109 --> 00:31:00,490
yeah we'll just watch this train for a
是啊，我们就只是看这列火车的

732
00:31:00,490 --> 00:31:10,890
few minutes
一会儿

733
00:31:10,890 --> 00:31:13,839
all right neural networks done training
 好的神经网络完成了训练

734
00:31:13,839 --> 00:31:18,099
and we've got our mixed image only took
我们的混合图像只是拍摄的

735
00:31:18,099 --> 00:31:23,289
me cool final image wow that looks
我很酷的最终形象哇看起来

736
00:31:23,289 --> 00:31:25,259
really gross
 真的很糟糕

737
00:31:25,259 --> 00:31:28,180
took me three minutes and 52 seconds to
 花了我3分52秒

738
00:31:28,180 --> 00:31:32,319
get to this final image here there you
得到这个最终的形象在这里有你

739
00:31:32,319 --> 00:31:39,849
go there's there is chlorophyll infested
 去那里有叶绿素出没

740
00:31:39,849 --> 00:31:45,339
willy wonka so he took the lines and
 willy wonka所以他采取了行和

741
00:31:45,339 --> 00:31:47,920
contours of this image pasted them into
 这张图片的轮廓将它们粘贴进去

742
00:31:47,920 --> 00:31:50,170
here the colors and textures of this
这里的颜色和纹理这

743
00:31:50,170 --> 00:31:52,660
image pasted them into here and we got
图像粘贴到这里，我们得到了

744
00:31:52,660 --> 00:31:57,579
this really gross looking willy wonka
这真是看起来很威利威尔卡

745
00:31:57,579 --> 00:32:00,579
mixed image using style transfer with a
 使用样式传输的混合图像

746
00:32:00,579 --> 00:32:04,119
neural network from lines so I want to
从线的神经网络，所以我想

747
00:32:04,119 --> 00:32:06,039
hammer these ideas into your head of
把这些想法锤入你的脑袋

748
00:32:06,039 --> 00:32:09,369
gradient descent loss functions and I
梯度下降损失函数和我

749
00:32:09,369 --> 00:32:10,630
want you to read about them on your own
 要你了解他们对自己的

750
00:32:10,630 --> 00:32:11,859
because they're super interesting and
 因为他们非常有趣

751
00:32:11,859 --> 00:32:13,210
really key to understanding neural
真正了解神经的关键

752
00:32:13,210 --> 00:32:15,579
networks and finally this idea of
网络，最后这个想法

753
00:32:15,579 --> 00:32:19,569
packages of help of using code that
 使用代码的帮助包

754
00:32:19,569 --> 00:32:21,099
other programmers have written and
 其他程序员写的和

755
00:32:21,099 --> 00:32:24,910
taking it to help ourselves and you know
拿它来帮助自己，你知道

756
00:32:24,910 --> 00:32:26,619
hopefully down the line as we become
 希望我们成为时候

757
00:32:26,619 --> 00:32:28,420
better and better programmers we're able
 我们能够做得越来越好的程序员

758
00:32:28,420 --> 00:32:30,460
to make our own code our own packages
使我们自己的代码成为我们自己的包

759
00:32:30,460 --> 00:32:32,680
that we can share with other programmers
 我们可以与其他程序员分享

760
00:32:32,680 --> 00:32:35,829
so I want you to take those three things
所以我希望你能把这三件事拿走

761
00:32:35,829 --> 00:32:38,759
gradient descent loss functions and
梯度下降损失函数和

762
00:32:38,759 --> 00:32:40,750
packages to help the world of
包帮助世界

763
00:32:40,750 --> 00:32:42,910
programming get better and I want you to
 编程变得更好，我要你

764
00:32:42,910 --> 00:32:45,250
take those ideas and think about them
接受这些想法并思考它们

765
00:32:45,250 --> 00:32:46,930
read more about them on your own time
 在自己的时间阅读更多关于它们的信息

766
00:32:46,930 --> 00:32:50,890
and yeah I hope you enjoyed this live
是的，我希望你喜欢这个生活

767
00:32:50,890 --> 00:32:53,200
coding portion of the style transfer
 风格转移的编码部分

768
00:32:53,200 --> 00:32:56,049
presentation I am Louis Gomez thank you
演讲我是路易斯戈麦斯谢谢你

769
00:32:56,049 --> 00:32:58,299
for your time and I'll see you guys
为你的时间，我会看到你们

770
00:32:58,299 --> 00:32:59,585
later bye
 后来再见

